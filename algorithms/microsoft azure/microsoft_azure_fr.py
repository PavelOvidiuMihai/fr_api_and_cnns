# -*- coding: utf-8 -*-
"""Microsoft Azure FR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o8eiEfm-Vpx-SBN0JEdeibRv621kg2B8
"""

from google.colab import drive
drive.mount('/content/gdrive')

!pip install Pillow
!pip install --upgrade azure-cognitiveservices-vision-face

import io
import os
import sys
import time
import uuid
import requests
from urllib.parse import urlparse
from io import BytesIO
from PIL import Image, ImageDraw
from azure.cognitiveservices.vision.face import FaceClient
from msrest.authentication import CognitiveServicesCredentials
from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person

#consts
dataset_path = "/content/gdrive/MyDrive/MIT_dataset/images/"
file_extension = ".jpg"
result_map = dict()
face_id_map = dict() 

# This key will serve all examples in this document.
KEY = "ed70949ab27b42c9a69347cfb9d38cf4"

# This endpoint will be used in all examples in this quickstart.
ENDPOINT = "https://ovidiu.cognitiveservices.azure.com/"

# Create an authenticated FaceClient.
face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))

def init():
  global result_map, face_id_map
  for filename in sorted(os.listdir(dataset_path)):
    #print(filename)
    key = filename.split('.')[0] #get file names without extension

    print("getting face id for ", key, "...")
    complete_file_path = dataset_path + key + file_extension
    face_id = detect_image(complete_file_path)
    face_id_map.update({key : face_id}) #insert face id in map
    
    result_map.update({key : None}) #insert keys in map

def detect_image(img_path, detection_model='detection_03'):
  detected_face = face_client.face.detect_with_stream(open((os.path.join(img_path)),'r+b'), detection_model=detection_model, return_face_id=True)
  
  if detected_face[0].face_id:
    return detected_face[0].face_id
  else:
    print("detect_image failed for: ", img_path)
    return None

def compare_images(face_id_1, face_id_2):

  if not face_id_1 or not face_id_2:
    print("compare_images failed for invalid face_id_1=", face_id_1, "or/and invalid face_id_2=", face_id_2)
    return None

  verify_result_same = face_client.face.verify_face_to_face(face_id_1, face_id_2)

  if verify_result_same:
    return round(float(verify_result_same.confidence) * 100,2)
  else:
    print("compare_images failed for face_id_1= ", face_id_1, " and face_id_2= ", face_id_2)
    return None

def add_results():
  global result_map, face_id_map

  for key1 in result_map.keys():

    person_confidence_score = dict()

    for key2 in face_id_map.keys():
    
      score = compare_images(face_id_map.get(key1), face_id_map.get(key2))
      print("key1:", key1, " key2:", key2, " score:", score)
      person_confidence_score.update({key2 : score})

    if person_confidence_score :
      result_map.update({key1 : person_confidence_score})

  #print(json.dumps(result_map, indent = 4))

def show_results():
  print("========================================FINAL RESULTS========================================")
  for key, person_confidence_score_map in sorted (result_map.items()):
    score = None
    if person_confidence_score_map is not None:
      score = person_confidence_score_map.values()

    print(key, ":", score)

init()
add_results()
show_results()

compare_images(face_id_map.get(face_id_map.keys()[0]), face_id_map.get(face_id_map.keys()[1]))